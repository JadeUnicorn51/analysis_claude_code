#!/usr/bin/env python3
"""
Universal Tool Framework AIæ™ºèƒ½æ¼”ç¤º

å±•ç¤ºæ¡†æ¶çš„AIæ™ºèƒ½æ ¸å¿ƒï¼šLLMé©±åŠ¨çš„ä»»åŠ¡åˆ†æã€æ™ºèƒ½è§„åˆ’ã€ä¸Šä¸‹æ–‡ç®¡ç†ç­‰
"""

import asyncio
import sys
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from utf import UniversalTaskEngine, FrameworkConfig
from utf.tools.file_tools import FileReadTool, FileWriteTool
from utf.tools.system_tools import GeneralProcessorTool
from utf.utils.logging import setup_logging
from utf.models.task import TaskStatus
from utf.ai.llm_client import LLMConfig, LLMProvider


class AIIntelligenceCLI:
    """AIæ™ºèƒ½æ¼”ç¤ºCLI"""
    
    def __init__(self):
        # åˆ›å»ºAIå¢å¼ºé…ç½®
        self.config = FrameworkConfig.create_default()
        
        # é…ç½®LLM (é»˜è®¤ä½¿ç”¨Mockï¼Œå¯ä»¥åˆ‡æ¢åˆ°çœŸå®LLM)
        self.config.llm_config = LLMConfig(
            provider="mock",  # å¯ä»¥æ”¹ä¸º "openai" å¦‚æœæœ‰APIå¯†é’¥
            model="mock-gpt-4",
            temperature=0.7,
            max_tokens=2000
        )
        
        # æ·»åŠ å·¥å…·
        self.config.add_tool(GeneralProcessorTool())
        self.config.add_tool(FileReadTool())
        self.config.add_tool(FileWriteTool())
        
        # å¯ç”¨AIç›¸å…³åŠŸèƒ½
        self.config.debug = True
        self.config.interaction.allow_user_interruption = True
        self.config.task.enable_auto_decomposition = True
        
        # è®¾ç½®æ—¥å¿—
        setup_logging(self.config.logging)
        
        # åˆ›å»ºAIå¢å¼ºå¼•æ“
        self.engine = UniversalTaskEngine(self.config)
        
        print("ğŸ¤– Universal Tool Framework - AIæ™ºèƒ½æ¼”ç¤º")
        print("=" * 60)
        print("âœ¨ AIæ™ºèƒ½ç‰¹æ€§:")
        print("  ğŸ§  LLMé©±åŠ¨çš„ä»»åŠ¡åˆ†æå’Œåˆ†è§£")
        print("  ğŸ¯ æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œæ‰§è¡Œè§„åˆ’")
        print("  ğŸ’­ ä¸Šä¸‹æ–‡è®°å¿†å’Œè¯­ä¹‰ç†è§£")
        print("  ğŸ”„ æ™ºèƒ½é”™è¯¯æ¢å¤å’Œé‡æ–°è§„åˆ’")
        print("  ğŸ“Š ä»»åŠ¡æ‰§è¡Œæ€»ç»“å’Œå»ºè®®")
        print()
        print(f"ğŸ”§ å½“å‰LLM: {self.config.llm_config.provider} ({self.config.llm_config.model})")
        print()
        print("ğŸ“‹ æ™ºèƒ½å‘½ä»¤:")
        print("  ask <é—®é¢˜>      - AIå¯¹è¯å’Œä»»åŠ¡æ‰§è¡Œ")
        print("  analyze <ä»»åŠ¡>  - åˆ†æä»»åŠ¡å¤æ‚åº¦")
        print("  context <ID>    - æŸ¥çœ‹ä»»åŠ¡ä¸Šä¸‹æ–‡")
        print("  memory          - æŸ¥çœ‹AIè®°å¿†ä½¿ç”¨")
        print("  resume <ID>     - æ™ºèƒ½æ¢å¤ä»»åŠ¡")
        print("  chat            - çº¯å¯¹è¯æ¨¡å¼")
        print("  demo            - è¿è¡ŒAIæ¼”ç¤º")
        print("  help            - æ˜¾ç¤ºå¸®åŠ©")
        print("  quit            - é€€å‡ºç¨‹åº")
        print("=" * 60)
    
    async def run(self):
        """è¿è¡ŒAIæ¼”ç¤ºCLI"""
        await self._run_startup_demo()
        
        while True:
            try:
                user_input = input("\nğŸ¤– AIåŠ©æ‰‹: ").strip()
                
                if not user_input:
                    continue
                
                parts = user_input.split(' ', 1)
                command = parts[0].lower()
                args = parts[1] if len(parts) > 1 else ""
                
                if command in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ AIåŠ©æ‰‹: å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸ºæ‚¨æœåŠ¡ï¼")
                    break
                
                elif command in ['help', 'h']:
                    await self.show_help()
                
                elif command == 'ask':
                    if args:
                        await self.ai_task_execution(args)
                    else:
                        print("âŒ è¯·æä¾›æ‚¨çš„é—®é¢˜æˆ–ä»»åŠ¡")
                
                elif command == 'analyze':
                    if args:
                        await self.analyze_task_complexity(args)
                    else:
                        print("âŒ è¯·æä¾›è¦åˆ†æçš„ä»»åŠ¡")
                
                elif command == 'context':
                    if args:
                        await self.show_task_context(args)
                    else:
                        print("âŒ è¯·æä¾›ä»»åŠ¡ID")
                
                elif command == 'memory':
                    await self.show_memory_usage()
                
                elif command == 'resume':
                    if args:
                        await self.intelligent_resume(args)
                    else:
                        print("âŒ è¯·æä¾›ä»»åŠ¡ID")
                
                elif command == 'chat':
                    await self.pure_chat_mode()
                
                elif command == 'demo':
                    await self.run_ai_demo()
                
                else:
                    # é»˜è®¤å½“ä½œAIå¯¹è¯å¤„ç†
                    await self.ai_task_execution(user_input)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                break
            except EOFError:
                print("\nğŸ‘‹ è¾“å…¥ç»“æŸï¼Œé€€å‡ºç¨‹åº")
                break
            except Exception as e:
                print(f"\nğŸ’¥ é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
    
    async def _run_startup_demo(self):
        """å¯åŠ¨æ¼”ç¤º"""
        print("\nğŸš€ å¯åŠ¨AIæ™ºèƒ½æ¼”ç¤º...")
        
        # æµ‹è¯•AIå“åº”
        try:
            health_ok = await self.engine.llm_client.health_check()
            if health_ok:
                print("âœ… AIæ™ºèƒ½å¼•æ“å·²å°±ç»ª")
            else:
                print("âš ï¸  AIå¼•æ“å¯åŠ¨ä¸­...")
        except Exception as e:
            print(f"âš ï¸  AIå¼•æ“åˆå§‹åŒ–è­¦å‘Š: {e}")
        
        print("ğŸ’¡ å°è¯•è¯´ï¼š'åˆ›å»ºä¸€ä¸ªåŒ…å«å½“å‰æ—¶é—´çš„æ–‡ä»¶' æˆ– 'åˆ†æè¿™ä¸ªé¡¹ç›®çš„ç»“æ„'")
    
    async def ai_task_execution(self, user_query: str):
        """AIé©±åŠ¨çš„ä»»åŠ¡æ‰§è¡Œ"""
        print(f"\nğŸ§  AIæ­£åœ¨åˆ†æ: {user_query}")
        print("-" * 50)
        
        start_time = time.time()
        task_completed = False
        ai_responses = []
        
        try:
            async for result in self.engine.execute_task(user_query):
                result_type = result.type
                result_data = result.data
                
                if result_type == "task_analysis_started":
                    print("ğŸ” AIå¼€å§‹æ™ºèƒ½åˆ†æä»»åŠ¡...")
                
                elif result_type == "complexity_analysis_completed":
                    complexity = result_data
                    print(f"ğŸ“Š AIå¤æ‚åº¦åˆ†æ:")
                    print(f"   ğŸ¯ æ™ºèƒ½è¯„åˆ†: {complexity['score']}/10")
                    print(f"   ğŸ§© éœ€è¦åˆ†è§£: {'æ˜¯' if complexity['needs_todo_list'] else 'å¦'}")
                    print(f"   ğŸ“ é¢„ä¼°æ­¥éª¤: {complexity['estimated_steps']} æ­¥")
                    print(f"   ğŸ”§ æ¨èå·¥å…·: {', '.join(complexity['required_tools'])}")
                    print(f"   ğŸ’­ AIåˆ†æ: {complexity['reasoning']}")
                
                elif result_type == "todo_list_generated":
                    todo_count = result_data.get('todo_count', 0)
                    print(f"\nğŸ¯ AIæ™ºèƒ½è§„åˆ’ ({todo_count} ä¸ªæ­¥éª¤):")
                    
                    todos = result_data.get('todos', [])
                    for i, todo in enumerate(todos, 1):
                        tools = ', '.join(todo.get('tools_needed', []))
                        priority = todo.get('priority', 0)
                        print(f"   {i}. {todo['content']}")
                        print(f"      ğŸ”§ å·¥å…·: {tools} | ä¼˜å…ˆçº§: {priority}")
                
                elif result_type == "todo_started":
                    todo = result_data.get('todo', {})
                    print(f"\nâ–¶ï¸  AIæ‰§è¡Œæ­¥éª¤: {todo.get('content', 'Unknown')}")
                
                elif result_type == "tool_execution_result":
                    tool_result = result_data
                    if tool_result.get('success', False):
                        print(f"   âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                        
                        # æ˜¾ç¤ºAIç”Ÿæˆçš„ç»“æœ
                        data = tool_result.get('data', {})
                        if isinstance(data, dict):
                            if 'message' in data:
                                print(f"   ğŸ’¬ AIç»“æœ: {data['message']}")
                            if 'file_path' in data:
                                print(f"   ğŸ“ æ–‡ä»¶: {data['file_path']}")
                    else:
                        error = tool_result.get('error', 'Unknown error')
                        print(f"   âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {error}")
                
                elif result_type == "todo_completed":
                    progress = result_data.get('progress', 0)
                    print(f"   âœ… æ­¥éª¤å®Œæˆ (AIè¿›åº¦: {progress:.1f}%)")
                
                elif result_type == "task_completed":
                    duration = time.time() - start_time
                    ai_summary = result_data.get('ai_summary', '')
                    task_completed = True
                    
                    print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆ! è€—æ—¶: {duration:.2f}ç§’")
                    if ai_summary:
                        print(f"ğŸ¤– AIæ€»ç»“: {ai_summary}")
                    break
                
                elif result_type == "task_failed":
                    error = result_data.get('error', 'Unknown error')
                    recovery_result = result_data.get('recovery_result', {})
                    task_completed = True
                    
                    print(f"\nğŸ’¥ ä»»åŠ¡å¤±è´¥: {error}")
                    if recovery_result:
                        print(f"ğŸ”„ AIæ¢å¤å°è¯•: {recovery_result.get('action', 'unknown')}")
                    break
            
            if not task_completed:
                print("âš ï¸  ä»»åŠ¡æ‰§è¡Œå¯èƒ½æœªå®Œæˆ")
                
        except Exception as e:
            print(f"ğŸ’¥ AIæ‰§è¡Œå¼‚å¸¸: {e}")
    
    async def analyze_task_complexity(self, task_query: str):
        """åˆ†æä»»åŠ¡å¤æ‚åº¦"""
        print(f"\nğŸ”¬ AIæ·±åº¦åˆ†æ: {task_query}")
        print("-" * 40)
        
        try:
            complexity = await self.engine.intelligent_planner.analyze_task_complexity(task_query)
            
            print("ğŸ“Š AIå¤æ‚åº¦åˆ†ææŠ¥å‘Š:")
            print(f"   ğŸ¯ å¤æ‚åº¦è¯„åˆ†: {complexity.score}/10")
            print(f"   ğŸ§© æ˜¯å¦éœ€è¦åˆ†è§£: {'æ˜¯' if complexity.needs_todo_list else 'å¦'}")
            print(f"   ğŸ“ é¢„ä¼°æ‰§è¡Œæ­¥éª¤: {complexity.estimated_steps}")
            print(f"   ğŸ”§ æ¨èå·¥å…·ç±»å‹: {', '.join(complexity.required_tools)}")
            print(f"   ğŸ’­ AIåˆ†æç†ç”±: {complexity.reasoning}")
            
            # åˆ†ç±»å»ºè®®
            if complexity.score <= 3:
                print("   ğŸ’¡ AIå»ºè®®: è¿™æ˜¯ä¸€ä¸ªç®€å•ä»»åŠ¡ï¼Œå¯ä»¥ç›´æ¥æ‰§è¡Œ")
            elif complexity.score <= 6:
                print("   ğŸ’¡ AIå»ºè®®: ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ï¼Œå»ºè®®åˆ†è§£ä¸ºå‡ ä¸ªæ­¥éª¤")
            else:
                print("   ğŸ’¡ AIå»ºè®®: å¤æ‚ä»»åŠ¡ï¼Œéœ€è¦ä»”ç»†è§„åˆ’å’Œå¤šæ­¥éª¤æ‰§è¡Œ")
            
        except Exception as e:
            print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
    
    async def show_task_context(self, task_id: str):
        """æ˜¾ç¤ºä»»åŠ¡ä¸Šä¸‹æ–‡"""
        print(f"\nğŸ’­ AIä¸Šä¸‹æ–‡è®°å¿†: {task_id}")
        print("-" * 40)
        
        try:
            context_stats = self.engine.context_manager.get_conversation_stats(task_id)
            
            if not context_stats:
                print("ğŸ“ è¯¥ä»»åŠ¡æš‚æ— ä¸Šä¸‹æ–‡è®°å½•")
                return
            
            print("ğŸ“Š ä¸Šä¸‹æ–‡ç»Ÿè®¡:")
            print(f"   ğŸ“ æ€»æ¡ç›®æ•°: {context_stats.get('total_entries', 0)}")
            print(f"   ğŸ“Š æ¡ç›®ç±»å‹: {context_stats.get('entry_types', {})}")
            print(f"   ğŸ“ æ€»é•¿åº¦: {context_stats.get('total_length', 0)} å­—ç¬¦")
            print(f"   ğŸ’¾ æ˜¯å¦æœ‰æ‘˜è¦: {'æ˜¯' if context_stats.get('has_summary') else 'å¦'}")
            print(f"   ğŸ•’ æœ€åæ›´æ–°: {context_stats.get('last_updated', 'N/A')}")
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
            summary = await self.engine.context_manager.summarize_conversation(task_id)
            if summary:
                print(f"\nğŸ“‹ AIä¸Šä¸‹æ–‡æ‘˜è¦:")
                print(f"   {summary}")
            
        except Exception as e:
            print(f"âŒ è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
    
    async def show_memory_usage(self):
        """æ˜¾ç¤ºAIè®°å¿†ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ§  AIè®°å¿†ç³»ç»ŸçŠ¶æ€")
        print("-" * 30)
        
        try:
            memory_stats = self.engine.context_manager.get_memory_usage()
            
            print("ğŸ“Š è®°å¿†ç»Ÿè®¡:")
            print(f"   ğŸ’¬ æ´»è·ƒå¯¹è¯æ•°: {memory_stats.get('conversations', 0)}")
            print(f"   ğŸ“ ä¸Šä¸‹æ–‡æ¡ç›®: {memory_stats.get('context_entries', 0)}")
            print(f"   ğŸ“š çŸ¥è¯†åº“æ¡ç›®: {memory_stats.get('knowledge_entries', 0)}")
            print(f"   ğŸ“ æ€»æ–‡æœ¬é•¿åº¦: {memory_stats.get('total_text_length', 0):,} å­—ç¬¦")
            print(f"   ğŸ’¾ é¢„ä¼°å†…å­˜: {memory_stats.get('estimated_memory_mb', 0):.2f} MB")
            
            # AIçŠ¶æ€
            ai_status = (await self.engine.get_system_status()).get('ai_status', {})
            print(f"\nğŸ¤– AIå¼•æ“çŠ¶æ€:")
            print(f"   ğŸ”§ LLMæä¾›å•†: {ai_status.get('llm_provider', 'Unknown')}")
            print(f"   ğŸ§  LLMæ¨¡å‹: {ai_status.get('llm_model', 'Unknown')}")
            
        except Exception as e:
            print(f"âŒ è·å–è®°å¿†çŠ¶æ€å¤±è´¥: {e}")
    
    async def intelligent_resume(self, task_id: str):
        """æ™ºèƒ½æ¢å¤ä»»åŠ¡"""
        print(f"\nğŸ”„ AIæ™ºèƒ½æ¢å¤ä»»åŠ¡: {task_id}")
        print("-" * 40)
        
        try:
            async for result in self.engine.resume_task(task_id):
                await self.display_task_result(result)
                
                if result.type in ["task_completed", "task_resume_failed"]:
                    break
        
        except Exception as e:
            print(f"ğŸ’¥ æ™ºèƒ½æ¢å¤å¼‚å¸¸: {e}")
    
    async def pure_chat_mode(self):
        """çº¯å¯¹è¯æ¨¡å¼"""
        print("\nğŸ’¬ è¿›å…¥AIå¯¹è¯æ¨¡å¼ (è¾“å…¥ 'exit' é€€å‡º)")
        print("-" * 40)
        
        while True:
            try:
                user_input = input("ä½ : ").strip()
                if user_input.lower() in ['exit', 'quit', 'é€€å‡º']:
                    print("AI: å¯¹è¯ç»“æŸï¼Œå›åˆ°ä¸»èœå•")
                    break
                
                if not user_input:
                    continue
                
                # ä½¿ç”¨LLMè¿›è¡Œå¯¹è¯
                from utf.ai.llm_client import LLMMessage
                messages = [
                    LLMMessage(role="system", content="ä½ æ˜¯Universal Tool Frameworkçš„AIåŠ©æ‰‹ï¼Œå‹å¥½ä¸”ä¸“ä¸šã€‚"),
                    LLMMessage(role="user", content=user_input)
                ]
                
                response = await self.engine.llm_client.chat_completion(messages)
                print(f"AI: {response.content}")
                
            except Exception as e:
                print(f"AI: æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé”™è¯¯: {e}")
    
    async def run_ai_demo(self):
        """è¿è¡ŒAIèƒ½åŠ›æ¼”ç¤º"""
        print("\nğŸ¬ AIæ™ºèƒ½èƒ½åŠ›æ¼”ç¤º")
        print("=" * 40)
        
        demo_tasks = [
            "è·å–å½“å‰æ—¶é—´å¹¶é—®å€™ç”¨æˆ·",
            "åˆ›å»ºä¸€ä¸ªåŒ…å«ç³»ç»Ÿä¿¡æ¯çš„æ–‡ä»¶",
            "åˆ†æè¿™ä¸ªé¡¹ç›®çš„ç»“æ„"
        ]
        
        for i, task in enumerate(demo_tasks, 1):
            print(f"\nğŸ¯ æ¼”ç¤º {i}: {task}")
            print("-" * 30)
            
            await self.ai_task_execution(task)
            
            if i < len(demo_tasks):
                print("\nâ¸ï¸  æŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ªæ¼”ç¤º...")
                input()
        
        print("\nğŸŠ AIæ¼”ç¤ºå®Œæˆï¼")
    
    async def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©"""
        print("\nğŸ“š AIæ™ºèƒ½åŠ©æ‰‹å¸®åŠ©")
        print("-" * 30)
        print("ğŸ¯ æ™ºèƒ½ä»»åŠ¡æ‰§è¡Œ:")
        print("   ask <ä»»åŠ¡>      - AIåˆ†æå¹¶æ‰§è¡Œä»»åŠ¡")
        print("   analyze <ä»»åŠ¡>  - åˆ†æä»»åŠ¡å¤æ‚åº¦")
        print("   demo            - è¿è¡ŒAIèƒ½åŠ›æ¼”ç¤º")
        print()
        print("ğŸ’­ ä¸Šä¸‹æ–‡å’Œè®°å¿†:")
        print("   context <ID>    - æŸ¥çœ‹ä»»åŠ¡ä¸Šä¸‹æ–‡")
        print("   memory          - æŸ¥çœ‹AIè®°å¿†çŠ¶æ€")
        print("   chat            - çº¯AIå¯¹è¯æ¨¡å¼")
        print()
        print("ğŸ”„ æ™ºèƒ½ç®¡ç†:")
        print("   resume <ID>     - æ™ºèƒ½æ¢å¤ä»»åŠ¡")
        print()
        print("ğŸ’¡ ç¤ºä¾‹ä»»åŠ¡:")
        print("   ask åˆ›å»ºä¸€ä¸ªåŒ…å«å½“å‰æ—¥æœŸçš„å¤‡å¿˜å½•")
        print("   ask åˆ†æè¿™ä¸ªæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰Pythonæ–‡ä»¶")
        print("   ask å¸®æˆ‘æ•´ç†é¡¹ç›®æ–‡æ¡£")
        print()
        print("ğŸ¤– AIç‰¹æ€§:")
        print("   - åŸºäºLLMçš„æ™ºèƒ½ä»»åŠ¡ç†è§£")
        print("   - è‡ªåŠ¨ä»»åŠ¡åˆ†è§£å’Œè§„åˆ’")
        print("   - ä¸Šä¸‹æ–‡è®°å¿†å’Œè¯­ä¹‰ç†è§£")
        print("   - æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œä¼˜åŒ–")
        print("   - é”™è¯¯åˆ†æå’Œæ¢å¤å»ºè®®")
    
    async def display_task_result(self, result):
        """æ˜¾ç¤ºä»»åŠ¡ç»“æœï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        result_type = result.type
        result_data = result.data
        
        if result_type == "task_resumed":
            progress = result_data.get('progress', 0)
            remaining = result_data.get('remaining_todos', 0)
            print(f"ğŸ”„ ä»»åŠ¡å·²æ¢å¤ (AIè¿›åº¦: {progress:.1f}%, å‰©ä½™: {remaining})")
        
        elif result_type == "task_completed":
            ai_summary = result_data.get('ai_summary', '')
            print(f"ğŸ‰ ä»»åŠ¡å®Œæˆ!")
            if ai_summary:
                print(f"ğŸ¤– AIæ€»ç»“: {ai_summary}")
        
        elif result_type == "task_resume_failed":
            error = result_data.get('error', 'Unknown')
            print(f"ğŸ’¥ æ¢å¤å¤±è´¥: {error}")


async def main():
    """ä¸»å‡½æ•°"""
    cli = AIIntelligenceCLI()
    await cli.run()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\nğŸ’¥ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
